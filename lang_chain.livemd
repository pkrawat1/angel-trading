# Langchain

```elixir
Mix.install([
  {:langchain, "~> 0.1.10"}
])
```

## Section

```elixir
defmodule MyApp do
  @pretend_db %{
    1 => %{user_id: 1, name: "Michael Johnson", account_type: :trial, favorite_animal: "Horse"},
    2 => %{user_id: 2, name: "Joan Jett", account_type: :member, favorite_animal: "Aardvark"}
  }

  def get_user_info(user_id) do
    @pretend_db[user_id]
  end
end
```

```elixir
alias LangChain.Function

function =
  Function.new!(%{
    name: "get_user_info",
    description: "Return JSON object of the current users's relevant information.",
    function: fn _args, %{user_id: user_id} = _context ->
      # Use the provided user_id context to call our Elixir function.
      # ChatGPT responses must be text. Convert the returned Map into JSON.
      Jason.encode!(MyApp.get_user_info(user_id))
    end
  })
```

```elixir
alias LangChain.Message

messages = [
  Message.new_system!(~s(You are a helpful haiku poem generating assistant.
    ONLY generate a haiku for users with an `account_type` of "member".
    If the user has an `account_type` of "trial", say you can't do it,
    but you would love to help them if they upgrade and become a member.)),
  Message.new_user!("The current user is requesting a Haiku poem about their favorite animal.")
]
```

```elixir
Application.put_env(:langchain, :google_ai_key, System.fetch_env!("LB_GOOGLEAI_API_KEY"))
```

```elixir
alias LangChain.ChatModels.ChatGoogleAI

chat_model =
  ChatGoogleAI.new!(%{endpoint: "https://generativelanguage.googleapis.com/", stream: true})
```

```elixir
context = %{user_id: 2}
```

```elixir
alias LangChain.Chains.LLMChain
alias LangChain.MessageDelta

callback = fn
  %MessageDelta{} = data ->
    # we received a piece of data
    IO.write(data.content)

  %Message{} = data ->
    # we received the finshed message once fully complete
    IO.puts("")
    IO.puts("")
    IO.inspect(data.content, label: "COMPLETED MESSAGE")
end

{:ok, updated_chain, response} =
  %{llm: chat_model, custom_context: context, verbose: true}
  |> LLMChain.new!()
  # add the prompt message
  |> LLMChain.add_messages(messages)
  # add the functions that are available to the LLM
  |> LLMChain.add_functions([function])
  # keep running the LLM chain against the LLM if needed to evaluate
  # function calls and provide a response.
  |> LLMChain.run(while_needs_response: true, callback_fn: callback)

response.content
```

```elixir
alias LangChain.Chains.LLMChain

{:ok, updated_chain, response} =
  updated_chain
  |> LLMChain.add_messages([Message.new_user!("Give me two more please!")])
  # keep running the LLM chain against the LLM if needed to evaluate
  # function calls and provide a response.
  |> LLMChain.run(while_needs_response: true)

IO.puts(response.content)
```

<!-- livebook:{"offset":2783,"stamp":{"token":"XCP.pSc05vRSBic6JxFbW73nz1MExehAOJkX8INy6MPGBLnroF6-omvErSzDj5oZNQSKnS2Ogo_MveDmX1EwcJKb8Y2RsWYtkfu9T5eO4-DiihDRlOOvlsOY87P-ZA","version":2}} -->
